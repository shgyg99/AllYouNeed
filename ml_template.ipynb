
# Machine Learning Workflow Template

## Step 1: Load the dataset
```python
import pandas as pd

def load_data(file_path):
    data = pd.read_csv(file_path)  # Change this if your data is in another format
    return data

# Example: Load data
data = load_data('your_dataset.csv')
data.head()
```

## Step 2: Explore and preprocess the data
```python
def preprocess_data(data):
    # Check for missing values
    print(data.isnull().sum())
    
    # Handle missing values if necessary
    data = data.dropna()  # Example: drop rows with missing values
    
    # Encode categorical variables (if applicable)
    data = pd.get_dummies(data)
    
    return data

# Example: Preprocess data
data = preprocess_data(data)
```

## Step 3: Feature and target separation
```python
def prepare_features_and_target(data, target_column):
    X = data.drop(columns=[target_column])
    y = data[target_column]
    return X, y

# Example: Prepare features and target
X, y = prepare_features_and_target(data, 'target_column_name')
```

## Step 4: Split data into training and testing sets
```python
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
```

## Step 5: Feature scaling (optional, but important for certain models)
```python
from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)
```

## Step 6: Train the model
```python
from sklearn.ensemble import RandomForestClassifier

def train_model(X_train, y_train):
    model = RandomForestClassifier(random_state=42)
    model.fit(X_train, y_train)
    return model

# Example: Train a Random Forest model
model = train_model(X_train, y_train)
```

## Step 7: Evaluate the model
```python
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
import seaborn as sns
import matplotlib.pyplot as plt

def evaluate_model(model, X_test, y_test):
    y_pred = model.predict(X_test)
    
    # Accuracy score
    accuracy = accuracy_score(y_test, y_pred)
    print(f"Accuracy: {accuracy:.2f}")
    
    # Confusion Matrix
    cm = confusion_matrix(y_test, y_pred)
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=model.classes_, yticklabels=model.classes_)
    plt.title("Confusion Matrix")
    plt.xlabel("Predicted")
    plt.ylabel("Actual")
    plt.show()
    
    # Classification Report
    print(classification_report(y_test, y_pred))

# Example: Evaluate the model
evaluate_model(model, X_test, y_test)
```

## Step 8: Save the model
```python
import joblib

def save_model(model, file_name):
    joblib.dump(model, file_name)
    print(f"Model saved as {file_name}")

# Example: Save the model
save_model(model, 'random_forest_model.pkl')
```

## Step 9: Load the saved model (for later use)
```python
def load_model(file_name):
    model = joblib.load(file_name)
    return model

# Example: Load the saved model
loaded_model = load_model('random_forest_model.pkl')
```

## Step 10: Make predictions with the loaded model
```python
def make_predictions(model, data):
    predictions = model.predict(data)
    return predictions

# Example: Make predictions with the loaded model
predictions = make_predictions(loaded_model, X_test)
print(predictions)
```
